\chapter{Evaluation}\label{chap:evaluation}

Having described the implementation of proposed reduction approaches, we can 
finally compare them. 
The goal of the comparison is to show that the slicing-based approach is 
the most practical minimization algorithm.

\section{Metrics}\label{chap:metrics}

There are several points of interest in this comparison. 
Each presented algorithm contained a description of this time complexity and 
its minimization properties. 
Due to this fact, we believe both the level of reduction and the algorithm's 
efficiency should be measured. 
In order to capture the performance of each approach, we employed 
the following metrics.
\begin{itemize}
\item This project focuses on minimality. 
  We want to test whether an algorithm produces the optimal result. 
  The \emph{minimality} metric is measured in two values: true and false. 
  True corresponds to the result being the desired minimal variant, while 
  false means that the result is suboptimal.
   We expect the naive and slicing-based algorithms to acquire significantly 
   more minimality than the Delta debugging approach.
  \item We have noted that some approaches, such as the minimizing Delta 
  debugging algorithm, do not achieve optimal reduction. 
  However, we can measure the ratio of the generated result compared to 
  the minimal variant. 
  The \emph{minimization ratio} will be measured in percentage. 
  The goal is to achieve $0\%$, which translates to the result being minimal.
  \item{Approaches} can be compared against each other using 
  a \emph{proportion ratio}. 
  This metric is also measured in percentage. 
  The number between $0\%$ and $100\%$ can be interpreted as the result's 
  proportion of the original program's size. 
  The lower the proportion ratio is, the better the algorithm is at source 
  code reduction.
  \item A straightforward way of measuring a program's performance is by 
  watching its \emph{execution time}. 
  The time will be measured in seconds and will serve as the primary 
  indicator of each algorithm's performance.
  \item The metric for testing heuristics is the \emph{processed variants} 
  count. 
  By counting how many actual results had to be generated and validated 
  before settling on the final output, we can evaluate the effectiveness of 
  a heuristic.
  The number of processed variants is compared with the expected number 
  of variants, i.e., the worst-case scenario.
\end{itemize}
By measuring these properties, we also observe whether the presented 
approaches struggle with a given input. 
Poor handling of specific inputs could also boil down to lacking 
implementation. 
However, we assume that errors in the implementation can be spotted in three 
ways. 
The program either throws an exception, produces an unreduced source code as 
its result, or outputs a program that does not result in the desired runtime 
error.

\section{Data set}

Each implemented approach works with three major input parts:
\begin{itemize}
  \item It receives the source code it should minimize.
  \item It is given a location of the desired runtime error.
  \item It requires a set of arguments used when running the input source 
  code, which leads to the mentioned runtime error.
\end{itemize}
Some approaches might benefit from other user inputs. 
For example, the implementation of the naive algorithm can cut the search 
short if it exceeds a given amount of variants. 
These inputs will be referred to as minor arguments.

Our dataset consists of 30 simple programs. 
Data for each program includes its source code written in C or C++, 
the target location, its execution arguments, and each approach's minor 
arguments. 
The dataset is made up of three equally-sized parts. 
Those parts differ based on the techniques used in their entries' source code. 
The first ten data entries represent non-structured programs. 
These entries contain source code exclusively in their \icode{main} function. 
Generally, they do not follow any specific programming paradigms and 
represent the simplest input type. 
The second part contains ten structured programs. 
The source code of these programs uses control flow statements, functions, 
and procedures. 
This type of input represents the regular program that this project is 
expected to handle. 
The last ten programs use aspects of object-oriented programming. 
Their code contains classes, inheritance, and polymorphism. 
Furthermore, the code is almost exclusively written in C++. 
However, advanced features of the language, such as templates, are omitted.

All three parts of the dataset are similar in terms of size. 
The source code for each program ranges from 30 to 100 lines. 
Moreover, the source code is contained in a single file. 
Therefore, the programs do not use any other include headers outside of 
system headers and standard libraries. 
Runtime errors in the dataset are caused mainly by invaliding an assertion. 
However, segmentation faults make up a large number of errors as well. 
We have also limited each program to cause only a single runtime error 
initially.

\section{Results}

We tested a total of three approaches. 
These include the naive approach with its heuristics, the minimizing Delta 
debugging approach, and the slicer-based approach 
with argument injection. 
The dataset was executed on a 6C/12T AMD Ryzen 5 5600X processor with 8GB of 
memory. 
Specifically, the chip was clocked at 4.85GHz for single-threaded tasks and 
4.5GHz for multi-threaded workloads. 
The naive approach ran parallelized on 12 threads, while other approaches 
ran single-threaded. 
The project was compiled using Clang 11.0.0 with high optimizations 
(\icode{-O2}) and ran on Ubuntu 20.04.2.0 LTS.

Table~\ref{tab:results} contains the results of all executed benchmarks. 
Each row represents a single entry from the data set. 
The entry has been used three times: in the naive approach, the Delta 
debugging algorithm, and the slicing-based approach. 
Those 30 rows thus represent a matrix of all executed runs and their results. 
Metrics introduced in Section~\ref{chap:metrics} are denoted as follows:
\begin{itemize}
  \item The \emph{minimization ratio} is represented by the $\mathcal{R}_m$ 
  column. 
  Values are in percentages.
  \item The binary \emph{minimality} metric does not have its column. 
  However, it can be derived from the $\mathcal{R}_m$ column by looking for 
  rows in which the value of $\mathcal{R}_m$ is zero.
  \item The \emph{proportion ratio} is represented by the $\mathcal{R}_p$ 
  column. 
  Values are in percentages and correspond to the ratio of input and output 
  sizes in bytes.
  \item Run's \emph{execution time} can be found in the $\Delta_t$ column. 
  Time is measured in the most relevant unit based on the run's duration.
  \item The \emph{processed variants count} is in the $\mathcal{I}_a$ column. 
  It can be directly compared to the $\mathcal{I}_e$ column. 
  $\mathcal{I}_e$ represents the expected number of processed variants - 
  the worst-case scenario.
\end{itemize}

\begin{table}[b!]\centering
\begin{tabular}{SSSSSSSSSSSSSS} \toprule
	 & & \multicolumn{4}{c}{Naive} & \multicolumn{4}{c}{Delta}  & \multicolumn{4}{c}{Slicing} \\
	 \cmidrule(l){3-6} \cmidrule(l){7-10} \cmidrule(l){11-14}
    {$Test$} & {$\mathcal{I}_e$} & {$\mathcal{I}_{a}$}  & {$\mathcal{R}_{m}$} & {$\mathcal{R}_{p}$} & {$\Delta_{t}$} & {$\mathcal{I}_{a}$} & {$\mathcal{R}_{m}$} & {$\mathcal{R}_{p}$} & {$\Delta_{t}$}  & {$\mathcal{I}_{a}$} & {$\mathcal{R}_{m}$} & {$\mathcal{R}_{p}$} & {$\Delta_{t}$}  \\ \midrule
    1  & {$2^{14}$} & 15 & 0.0 & 0.0 & 0.581s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
	2  & {$2^{19}$} & 567 & 7.3 & 0.0 & 2.448s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    3  & {$2^{10}$} & 1186 & 0.0 & 0.0 & 0.715s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    4  & {$2^{26}$} & 761 & 0.0 & 0.0 & 1m34s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    5  & {$2^{15}$} & 615 & 0.0 & 0.0 & 1.364s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\ \midrule
    6  & {$2^{11}$} & 4 & 0.0 & 0.0 & 0.519s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    7  & {$2^{31}$} & 915 & 16.7 & 0.0 & 29m7s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    8  & {$2^{40}$} & 465 & 4.2 & 0.0 & 47m59s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    9  & {$2^{13}$} & 17 & 0.0 & 0.0 & 1.848s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    10 & {$2^{16}$} & 61 & 0.0 & 0.0 & 8.155s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\ \midrule
    11 & {$2^{18}$} & 37 & 0.0 & 0.0 & 55.168s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    12 & {$2^{22}$} & 18 & 7.1 & 0.0 & 2m14s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    13 & {$2^{14}$} & 138 & 0.0 & 0.0 & 0.917s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    14 & {$2^{16}$} & 84 & 0.0 & 0.0 & 16.189s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    15 & {$2^{10}$} & 9 & 0.0 & 0.0 & 0.534s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\ \midrule
    16 & {$2^{13}$} & 14 & 0.0 & 0.0 & 0.783s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    17 & {$2^{11}$} & 31 & 0.0 & 0.0 & 0.634s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    18 & {$2^{34}$} & 2156 & 19.9 & 0.0 & 38m13s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    19 & {$2^{27}$} & 1654 & 14.0 & 0.0 & 14m6s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    20 & {$2^{14}$} & 276 & 0.0 & 0.0 & 1.003s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\ \midrule
    21 & {$2^{22}$} & 315 & 0.0 & 0.0 & 2m35s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    22 & {$2^{24}$} & 546 & 0.0 & 0.0 & 11m52s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    23 & {$2^{19}$} & 34 & 33.3 & 0.0 & 1m2s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    24 & {$2^{18}$} & 12 & 0.0 & 0.0 & 1m33s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    25 & {$2^{24}$} & 463 & 5.8 & 0.0 & 5m9s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\ \midrule
    26 & {$2^{20}$} & 154 & 0.0 & 0.0 & 3m25s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    27 & {$2^{15}$} & 93 & 0.0 & 0.0 & 2.018s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    28 & {$2^{21}$} & 75 & 0.0 & 0.0 &  & 2m15s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    29 & {$2^{14}$} & 140 & 21.8 & 0.0 & 0.882s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\
    30 & {$2^{16}$} & 168 & 0.0 & 0.0 & 4.333s & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0  \\ \bottomrule
\end{tabular}
\caption{A benchmark of the three minimization approaches.}
\label{tab:results}
\end{table}